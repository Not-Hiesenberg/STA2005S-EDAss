---
title: "To Oil or Not to Oil: An Investigation into Agrabathi and Old Wive's Tales"
author: "Dhiya Tathiah and Keeran Moodley"
format:
  pdf:
    pdf-engine: latexmk
    latex-auto-install: true
    include-in-header:
      - file: preamble.tex
    toc: true
    number-sections: true
    colorlinks: true
    
execute: 
  echo: false
  eval: true
  output: false
filters:
  - parse-latex
---

```{r setup}
library(dplyr)
library(pastecs)
library(dplyr)
library(kableExtra)
library(car)
library(psych)
```







\newpage
# Introduction 
Incense sticks, or Agrabathi, have been a part of cultural and spiritual practices for centuries, especially in the Indian subcontinent. These fragrant sticks are commonly used in religious rituals, meditation, and household ceremonies, where their slow, steady burn releases aromatic smoke that permeates the air. The burning of incense is more than just a sensory experience—it holds deep cultural significance, symbolizing the connection between the physical and the spiritual realms.

However, despite the widespread use of incense sticks, little scientific research has been done to investigate factors that might influence their burn time. There is an abundance of varying anecdotal theories which all claim to alter the burn rate of Agrabathi, but these claim remains largely unexamined. This assignment will explore one such claim: the influence of different oils on the burn rate of Agrabathi. 

# Motivation
For generations, families across the Indian subcontinent have followed a long-held belief that applying oil to incense sticks, known as Agrabathi, causes them to burn faster. This old-wives tale, passed down through the ages, was believed to ensure that the sacred smoke swiftly filled the home with fragrance, creating an atmosphere for prayer and meditation. The faster burning time, in particular, was thought to facilitate a stronger connection with the divine, symbolizing the quick ascent of prayers to the heavens. 

While the cultural and spiritual significance of incense sticks is undeniable in Indian homes, there remains a question: does applying oil to incense sticks truly accelerate burn time? This study seeks to investigate the validity of this age-old belief, providing modern families with data to determine whether applying oils such as castor and coconut oil is a meaningful practice or simply a tradition without scientific support.

By scientifically evaluating the effects of applying oils to incense sticks, we aim to empower families to make informed choices about their usage, potentially saving costs on unnecessary oils if they are found to have no significant effect. This experiment not only seeks to reveal the truth behind the belief but also strives to contribute practical knowledge to everyday practices that have long been part of cultural rituals. 

# Objectives
Our objective is to determine which treatment has an effect on burn time looking at three treatment: a control, castor oil, and coconut oil. We will examine whether these commonly used oils differ from each other (comparison of castor and coconut oil) and whether there is a difference with the oils from the control (comparing each oil individually to the control). By acknowledging the differences that might arise due to manufacturing or material quality, blocking for brands serves as a crucial step in isolating the true effects of the oil treatments. By structuring the experiment in this way, we aim to minimize the impact of confounding variables, allowing us to attribute any variations in burn time more confidently to the treatments themselves rather than to the intrinsic characteristics of the incense sticks. Once the incense sticks are lit and the smoke clears, the last Agrabathi stick will reveal whether oils truly influence burn time. By repeating this experiment, we ensure that our findings are as robust as the scent that lingers in the air.

Formally this study will test the following hypothesis:

::: {.callout-note appearance="simple"}
$H_0$: The application of different oils has no effect on the burn time of Agrabathi

$H_A$: The application of at least one of the oils has an effect on the burn time of Agrabathi
:::
Additionally the following two comparisons of means will be conducted:

::: {.callout-note appearance="simple"}
$L_1$: Effect of castor oil is equal to the effect of coconut oil. 

$L_2$: The effect of no oil is equal to the average effect of applying the oils
:::
 

# Design and Procedure

This experiment will employ a randomised block design with a single treatment factor - application of oil - of three levels, viz., control (no oil), coconut oil, and castor oil. The experiment will block for heterogeneity of experimental units arising from the use of different brands of Agrabathi viz., Hem, Malarani and Tulasi. 

The factor levels have been selected as they are oils commonly used in Indian households across the world and are the de facto choices during day to day use. The brands of Agrabathi from which the experimental units are drawn from represent easily found and widely exported brands.

By acknowledging the differences that might arise due to manufacturing or material quality, blocking for brands serves as a crucial step in isolating the true effects of the oil treatments. By structuring the experiment in this way, the study aims to minimize the impact of confounding variables, allowing for the attribution of any variations in burn time more confidently to the treatments themselves rather than to the intrinsic characteristics of the incense sticks.

A pilot study will be conducted to assess the viability of the experimental procedure which is outlined below:

1. Select experimental units from each brand of Agrabathi
2. Randomly assign treatments to the units within each block
3. Apply the relevant treatment in the form of coating the sticks of Agrabathi in the appropriate oil ensuring that there is even and consistent covering
4. Light the Agrabathi sticks at their tip and place them in a sheltered area to burn
5. Record the time taken of the Agrabathi to completely burn

Precise details about the randomisation procedure will be discussed in \todo{Link to the relevant section}.

To reduce variance in the experiment due to external factors several steps will be taken to ensure that the experimental conditions will be kept consistent:

1. The Agrabathi will be burnt in the same area to prevent confounding due to location
2. The Agrabathi will be sheltered from wind and sunlight to prevent confounding due to increased airflow over the flaming tip and increased energy due to the sunlight
3. The blocks will be burnt at 10 minute intervals from each other to reduce confounding due to time. The interval is given to allow for the experimenters to set up and light the Agrabathi. This also allows for the majority of the Agrabathi in each group to burn concurrently to further reduce confounding due to time as well as increase the efficiency of the experiment.

 The response variable is the time taken for the Agrabathi to burn given in seconds. The measurement of this was achieved via online stopwatch websites and the data was then manually transcribed.

# Randomisation
Randomisation took place within each block of 3 experimental units (EUs). The procedure was as follows:

1. Label the EUs 1-3
2. Generate three random numbers between 1 and 1000 and iteratively assign them to the EUs (first generated number to EU 1, etc.)
3. Sort the random numbers in ascending order
4. Assign the treatments to the EUs using this ordered list, i.e., the EU corresponding to the lowest random number will be assigned the control treatment of no oil, the second number will get the coconut oil treatment and the largest number will get the castor oil treatment
5. Repeat 1-4 for all three blocks
6. Repeat 1-5 for every replication of the experiment

A sample randomisation for a singly replicated experiment is given below:

```{r}
#| output: true
#example randomisation

sampRand <-data.frame()

for (i in 1:3){
set.seed(sample(1:1000000))
randOrd<-sample(1:1000,3)
sorted<-sort(randOrd)
treat<-match(sorted,randOrd)
treat<-replace(treat, TRUE, LETTERS[unlist(treat)])
sampRand<- rbind(sampRand,treat)
}
colnames(sampRand)<-c(1,2,3)
rownames(sampRand)<-c("Hem", "Malarani" , "Tulasi")
kbl(sampRand, format="latex",booktabs=TRUE, caption="Sample Randomisation")|>
kable_styling(position = "center", latex_options="hold_position")
```
Where A,B, and C correspond to the treatment of no oil, coconut oil and castor oil respectively. The full randomisation used is given in the Appendix.


# Pilot study
The pilot study was run with 18 experimental units and blocks were replicated twice. 

Several difficulties were experienced while conducting the pilot study. Due to the large volume of smoke produced by the Agrabathi as it burnt, the experiment had to be conducted outdoors. This made it difficult to control for environmental factors such as wind, humidity, and sunlight. Additionally it was difficult to determine exactly when the Agrabathi stopped burning and thus there are slight non-systematic errors in the measurements of the burn times due to experimental error. 

The original data is provided in the appendix. A basic descriptive analysis was conducted to analyse the data:

```{r pilot data wrangling}
#Data wrangling and clean up
pilotBurn <- read.csv("AgrabathiBurnTimePilotData.csv")
pilotBurn$time <- pilotBurn$min*60+pilotBurn$sec
pilotBurn$min<- NULL
pilotBurn$sec <- NULL
pilotBurn$block <- factor(pilotBurn$block,levels=c(1,2,3), labels =c("Hem", "Malarani" , "Tulasi"))
pilotBurn$treat<- factor(pilotBurn$treat, levels=c("A","B","C"), labels=c("No oil", "Coconut oil", "Castor oil"))
```

```{r Descriptive stats}
#| output: true
#

descstats<-by(pilotBurn$time, pilotBurn$treat, stat.desc)
summaryData<- data.frame()
for (block in descstats){
  block<-unname(block)
  summaryData<-rbind(summaryData, data.frame(Median=block[8],Mean=block[9],SD=block[13]))
}
row.names(summaryData)<-c("Control", "Coconut Oil" , "Castor Oil")

kbl(summaryData,digits=2, format="latex",booktabs=TRUE, caption="Basic descriptive statistics")|>
kable_styling(position = "center", latex_options="hold_position")

```
The grand mean is `{r} round(mean(pilotBurn$time),2)` and grand sample standard deviation is `{r} round(sd(pilotBurn$time),2)`.
From Table 1, one notes some differences in the means across the three treatments. The control group shows the lowest mean burn time but displays the highest standard deviation out of all the treatments. This may be due to the heterogeneity of experimental units. The oil treatments show smaller standard deviations which may be indicative of a treatment effect. Additionally all three treatments display a positive skew. These insights suggest a need for more data to test for significant effects.

# Data collection and Assumptions
```{r}
# Data wrangling for generated data
genBurn <- read.csv("AgrabathiBurnTimeGeneratedData.csv")
genBurn$block<- as.integer(genBurn$block)

genBurn$block <- factor(genBurn$block,levels=c(1,2,3), labels =c("Hem", "Malarani" , "Tulasi"))
genBurn$treat<- factor(genBurn$treat, levels=c("A","B","C"), labels=c("No oil", "Coconut oil", "Castor oil"))

```


The full experiment was run with 30 replications per block. This took place using the same experimental and randomisation procedure as outlined above. The original data is given in the Appendix.


Normality tests were then conducted to justify the assumptions which will be made (discussed in the next section) in the model. \todo{Add in all of Dhiya's analysis here and typeset}

```{r}
#| output: true
#| fig-align: center
#| fig-cap: "Box plot of brands versus burn time"
#| label: fig-box1

par(mfrow=c(1,1))
boxplot(time ~ block, data=genBurn, ylab="Burn Time (seconds)", xlab=" Brands", las=1, main="Boxplot of Blocks", col="pink")
```
In  @fig-box1, there is an equal proportion of the inner quartile range both above and below the mean and the tails of the boxplots are symmetrical, these properties are evidence that the data follows a normal distribution. In a randomized block design, it's important to check if the data within each block follows a normal distribution. This helps ensure that the residuals of the ANOVA model are likely to be normally distributed, which is a key assumption for the validity of the F-tests. 

Non-normality may indicate potential issues like outliers or skewed data, which could violate ANOVA's assumptions and lead to inaccurate conclusions. It is visually clear from @fig-box1 that the data is normal. The whiskers on the box plots are approximately equal across the blocks, yet slightly shorter for ‘Hem’ than ‘Malarani’ or ‘Tulasi’. Due to an approximate average length of whiskers across the blocks, one can conclude equal variances. A Levene test is nevertheless performed to ensure accuracy since there is some disparity within the ‘Hem’ block of this exploratory analysis.\newpage
```{r}
#| output: true
#| fig-align: center
#| fig-cap: "Box plot of brands and treatments versus burn time"
#| label: fig-box2
#| fig-pos: 'h'
boxplot(time ~ treat+block, data=genBurn, ylab="Burn Time (seconds)", xlab=c("A1","A2","A3"), las=1, main="Boxplots of Treatments and Blocks")
```
@fig-box2 delves into the treatments within the blocks.
Within block 1:

1. Treatment 1: The burn times are clustered, a small interquartile range and short, symmetric tails.
2. Treatment 2: The median is approximately the same as treatment 1 (control) yet a larger variability is evident. The lower tail seems to be slightly longer than the upper tail indicating a possible left skew (even though very small difference in tail length).
3. Treatment 3:  High variability, clear positive skew due to a longer upper tail. The median is marginally above the median for Treatment 1 & 2. The large spread suggests increased burn time under this treatment. 


With Block 2:

1. Treatment 1: Significantly lower median compared to other treatments in block 2. There is a positive skew due to a longer upper tail. There is a much lower median present compared to the same treatment in block 1. 
2. Treatment 2: There is an outlier present in this data, suggesting that we have an observation which is quite far from the rest of the data. The median is the highest in this block even though the data is grouped quite closely (smallest IQR of block 2). The entire distribution is shifted upward relative to treatment 1 in this block yet treatment 2’s lower quartile overlaps with the upper quartile of treatment 1.
3. Treatment 3: High Variability and is potentially right skewed. 

Within Block 3: 

1. Treatment 1:  Lowest median in this block and overall blocks, there is a clear left-skew due to asymmetric tail length. 
2. Treatment 2: Symmetric tails and median which appears to be in the center of the IQR, larger variability compared to Treatment 2 in the other 2 blocks (longer tails).
3. Treatment 3: Highest median in this block with a symmetrical box plot (central median and approximately equal tail length). 


The overall impression of this more in-depth analysis of the box plots does seem to indicate some inconsistencies which do not represent an accurate normal distribution with homoscedasticity. This is due to asymmetric tail lengths, non-central medians and tail lengths of treatments which are not consistent throughout blocks. While there are these indications of a stray from a normal distribution, an inspection of the Shapiro Wilk normality test will test if this is a result of significant non-normality or simple randomness within the data. 

```{r}
#| output: false

x<-as.numeric(unname(unlist(shapiro.test(genBurn$time))[2]))
```
The null hypothesis for this test would be that the data is normally distributed while the alternate hypothesis would be that the data follows a different distribution. Since our $p$-value is quite large $p=$ `{r} round(x,4)` $>0.5$, therefore there is insufficient evidence to reject the null hypothesis, thus the distribution of the reponse variable is normal.
```{r}
#| output: true
#Mainly estimates
final<-aov(time ~ treat+block, data=genBurn)
#final
#model.tables(final,"means")#Gives the mean
#model.tables(final, se=T)#Gives the standard error of effects
treat<-as.factor(genBurn$treat)
par(mfrow=c(2,3))
plot(final)

#Normality tests
hist(resid(final), main=" ", las=1, breaks=10)
shapiro.test(resid(final))
```


```{r}
#| output: true
#Checking equal variance
homo<-as.numeric(unlist(leveneTest(time ~ treat, data=genBurn))[5]) #Test for Homogeneity of Variances
#Levene's test evaluates whether the variances of different groups are significantly different from each other.

par(mfrow=c(1,2))
hist(genBurn$time, main="Histogram illustrating the distribution of burn times", las=1, xlab="Burn Time")
qqPlot(genBurn$time)

shapiro.test(genBurn$time)

```

Interpretation of effects:
The effects of the treatments indicate how each oil influences the burn time of the incense sticks relative to the average burn time:
 ‘No oil’ results in a shorter burn time by 412.7 seconds compared to the baseline, suggesting that oil treatments extend the burn duration.
 ‘Coconut oil’ increases the burn time by 166.7 seconds, indicating a moderate effect compared to the baseline.
 ‘Castor oil’ has the largest effect, increasing the burn time by 246.1 seconds, making it the most effective treatment for extending the burn time.
This suggests that both oils significantly increase the burn time of the incense sticks, with ‘castor oil’ being the most effective. The negative effect of ‘No oil" reinforces that the oils play a role in slowing the burn rate.
The standard error for the treatment effect is 127.3 seconds, which gives us an idea of the precision of the estimated treatment effects. A smaller standard error would indicate more precise estimates, but in this case, a standard error of 127.3 seconds suggests some level of uncertainty in the treatment effect estimates.
The standard error for replication is relatively small at 30 seconds, indicating that the variability within the blocks or experimental units is low. This reflects that the blocking (by brand) helped reduce some variability in the experiment.
Given the small p value from the ANOVA, we can confidently conclude that the observed differences between treatments are statistically significant. This suggests that the treatment effects are unlikely to be due to random variation alone. Despite the moderately large standard error for the treatment effects (127.3 seconds), the small p-value indicates that the effects of the treatments, particularly castor oil, are statistically significant and not likely due to chance. Therefore, the large treatment effects are statistically meaningful.
In summary, the effects indicate that applying oils, particularly castor oil, increases the burn time of incense sticks. The small p-value supports the statistical significance of these effects, despite the presence of some uncertainty in the precision of the estimates due to the standard error.

In figure 1, there is an equal proportion of the inner quartile range both above and below the mean and the tails of the boxplots are symmetrical, these properties are evidence that the data follows a normal distribution. In a randomized block design, it's important to check if the data within each block follows a normal distribution. This helps ensure that the residuals of the ANOVA model are likely to be normally distributed, which is a key assumption for the validity of the F-tests. Non-normality may indicate potential issues like outliers or skewed data, which could violate ANOVA's assumptions and lead to inaccurate conclusions. It is visually clear from figure one that our data is normal. The whiskers on the boxplots are approximately equal across the blocks, yet slightly shorter for ‘Hem’ than ‘Malarani’ or ‘Tulasi’. Due to an approximate average length of whiskers across the blocks, we can conclude equal variances, yet a Levene test will be performed to ensure accuracy since there is some disparity within the ‘Hem’ block of this exploratory analysis. 
A further delve into the treatments within the blocks (figure 2):
In Block 1: 
Treatment 1: The burn times are clustered, they have a small interquartile range (IQR) and short, symmetric tails. 
Treatment 2: The median is approximately the same at treatment 1 (control) yet a larger variability is evident. The lower tail seems to be slightly longer than the upper tail indicating a possible left skew (even though a very small difference in tail length is present).
Treatment 3:  From this boxplot, we can see large amounts of variability,a definite positive skew due to a longer upper tail. The median is marginally above the median for Treatment 1 & 2. The large spread suggests increased burn time under this treatment. 
In Block 2:
Treatment 1: There is a significantly lower median compared to other treatments in block 2. There is a positive skew due to a longer upper tail. There is a much lower median present compared to the same treatment in block 1. 
Treatment 2: An outlier is present in this data, suggesting that we have an observation which is quite far from the rest of the data. The median is the highest in this block even though the data is grouped quite closely (smallest IQR of block 2). The entire distribution is shifted upward relative to treatment 1 in this block yet treatment 2’s lower quartile overlaps with the upper quartile of treatment 1.
Treatment 3: High amounts of variability is present and data is potentially right skewed. 
In Block 3: 
Treatment 1:  Lowest median in this block and overall blocks, there is a clear left-skew due to asymmetric tail length. 
Treatment 2: Tails are symmetric and the median appears to be in the center of the IQR, larger variability compared to Treatment 2 in the other 2 blocks (longer tails).
Treatment 3: Highest median in block 3 with a symmetrical boxplot (central median and approximately equal tail length). 
The overall impression of this more in-depth analysis of the boxplots does seem to indicate some inconsistencies which do not represent an accurate normal distribution with homoscedasticity. This is due to asymmetric tail lengths, non-central medians and tail lengths of treatments which are not consistent throughout blocks. While there are these indications of a stray from a normal distribution, an inspection of an interaction plot and the Shapiro Wilk normality test. These should assist us in determining whether our data is normal or not and whether this is due to a combined effect influencing our data which we did not account for. The variability among blocks and treatments will also be further explored by means of a Levene test and in our ANOVA analysis to determine whether these differences are statistically significant. 

Interaction plot:
The interaction plot reveals that the relationship between the treatment (No oil, Coconut oil, Castor oil) and burn time varies depending on the brand of incense stick (Malarani, Hem, Tulasi), indicating a potential interaction effect. For example, Malarani shows a large difference in burn times between "No oil" and "Castor oil," while Hem shows a smaller difference, suggesting the oils have less impact on burn time for Hem sticks. Tulasi exhibits moderate differences but generally has lower burn times across all treatments. The non-parallel lines in the plot confirm that the effect of the treatments differs across brands, which is indicative of an interaction. However, despite the visual evidence of interaction, the large p-value (insert p value) from the ANOVA suggests that this interaction is not statistically significant, implying that the observed differences in treatment effects across brands could be due to random variation rather than a meaningful interaction.

Shapiro Wilk Normality Test:
W = 0.98771, p-value = 0.5643
The null hypothesis for this test would be that the data is normally distributed while the alternate hypothesis would be that the data follows a different distribution. Since our p value is quite large p>0.5, therefore we fail to reject the null hypothesis concluding the distribution is normal. 
 
Above (histogram and QQplot): (Yet our Levene Test is secure so there is a homoscedasticity)
The Q-Q plot suggests that the central portion of the burn time data follows a normal distribution reasonably well, as the points around the middle of the plot lie close to the straight line. However, there are notable deviations at both ends, with the lower tail showing lighter-than-expected behavior (fewer extreme small values) and the upper tail indicating heavier-than-expected values (more extreme large values). These deviations from the line, particularly at the tails, suggest that the data does not fully adhere to the assumption of normality. The plot shows a blue confidence band. Points falling within this band suggest acceptable deviations from normality. However, several points in the tails fall outside the band, strengthening the evidence of non-normality in the extremes.
The histogram of burn time data appears to have a slight right skew. Most of the burn time values are concentrated between 1,500 and 3,500, with a peak frequency around 2,500. There are a few observations with higher burn times, reaching up to 4,000, which contribute to the right tail. This skewness aligns with what is seen in the Q-Q plot, where the points in the upper quantiles deviate above the line, indicating heavier tails on the right side. While the overall distribution of burn times does not seem to be drastically skewed, the deviations in the tail could suggest a slight departure from normality, as indicated by both the histogram and the Q-Q plot.
 

Fitted Vs residual and Scale Location plot:
There is no funnel shape (no widening or narrowing or the spread of residuals in data) present in the Fitted vs residual plot, therefore no indication of heteroscedasticity. There is no discernible pattern regarding the residuals around the horizontal 0 line. 
Scale Location has a slightly decreasing red line, it suggests that the spread of residuals (i.e., the variability of the residuals) decreases as the fitted values increase. This indicates that the model might exhibit heteroscedasticity, where the variance of the residuals is not constant across the range of the fitted values. In this case, the residuals show less variability at higher fitted values compared to lower fitted values.
 Levene test:
The P value =0.4419 indicating that there is homogeneity present in the variances. 

The histogram of the residuals show a bell-shaped curve which is a well-known characteristic of a normal distribution. There is asymmetry present, indicating there are more positive residuals than negative ones (prediction is lower than our observed value) which signals that our assumption of normality might be violated. Yet the Shapiro Test confirms normality. 


```{r}
#interaction plots

```
 Interaction plot: (We can use blocking on x axis or as the lines yet give different plots)
*Still uncertain whether should be included or not **Question for tutors. 
Since there is no overlap or intersection between the lines and they are parallel -> no interaction. 
OR: interaction.
 
 




# Model
This study will employ the following model for the data:
$$ Y_{ij}= \mu+ \alpha_i+ \beta_j+ (\alpha\beta)_{ij}+\varepsilon_{ij} $$
Where $\varepsilon\sim N(0,\sigma^2)$ is the error term, $1\leq i\leq 3$ indexes the treatments, $1\leq j\leq 3$ indexes the blocks. Additionally we employ the sum to zero constraint such that $\sum_{i=1}^{3}{\alpha_i}=\sum_{j=1}^{3}{\beta_j}=\sum_{ij}{(\alpha\beta)_{ij}}=0$. Additionally we assume an interactive model and thus include the possibility of interaction between block and treatment effects.

Each of these terms are interpreted as follows:

1. $\mu$ is the overall mean
2. $\alpha_i$ is the main effect of the $i$-th level of the treatment factor (oil application)
3. $\beta_j$ is the main effect of of the $j$-th level of the blocking factor (brand)
4. $(\alpha\beta)_{ij}$ is the interaction between the $i$-th level of the treatment and the $j$-th level of the blocking factor.

This model will make the following assumptions:

1. Homoscedasticity
2. Normally distributed error terms
3. Independent observations

These assumptions will be justified and assessed during the model checking stage of the paper.

# Outline of Analysis
The analysis of results will aim to provide conclusive evidence to support or reject the a priori hypothesis of this study as well as evaluate the root causes of these results my means of analysing the contrasts of interest.
\newpage
# ANOVA

Based on the above model an ANOVA was performed to determine if the treatments have a significant effect on the burn time of Agrabathi.
```{r}
#| output: true
anova<-aov(time ~ block + treat, data=genBurn)
tab<-unlist(summary(anova))

df<-data.frame(labs=c(1,2,3))
for(i in c(1,4,7,10,13)){#row indexing
  df<-cbind(df,data.frame(unlist(tab[i:(i+2)])))
}
df$labs=NULL
rownames(df)<-c("Block","Treatment","Error")
colnames(df)<-c("DF","SS","MSS","F","P(>F)")

kbl(df,digits=c(1,1,1,3,7), format="latex",booktabs=TRUE, caption="Analysis of Variance")|>
kable_styling(position = "center", latex_options="hold_position")

```

Blocks: The F-value for blocks is $19.27$ with a very low $p$-value ($p=1.00\times10^{-7}$), indicating that the variability between blocks is highly significant and thus it was reasonable to block for the brands of Agrabathi used.
Treatments: The F-value for treatments is $11.33$ with a low $p$-value ($p=4.34\times 10^{-5}$), suggesting that the differences between treatments are also significant. This is to say that the application of one of the treatments has an effect on the burn time of Agrabathi. At this stage it is unclear which treatment (or even the control) is responsible for this conclusion. The specific cause of this effect is analysed more deeply by the contrasts considered in the following section.
Significance of Block Effect: The significant p-value for blocks suggests that differences between blocks are substantial, meaning that the block effect is crucial in explaining the variability in burn time.
Significance of Treatment Effect: The significant $p$-value for treatments indicates that the treatments have a meaningful impact on burn time, suggesting that different treatments result in different burn times.
Residuals: The residuals provide insight into the unexplained variation after accounting for block and treatment effects. Although this variation is present, it's relatively small compared to the explained variance from blocks and treatments. 
Since the p value<0.05 for both treatment and block effect, we can reject the null hypothesis and conclude that different oils (treatments) and brands (blocking factors) affect the burn time of incense sticks. 

# Contrasts
This study examines 2 planned contrasts, viz., if there is a difference in the burn time of Agrabathi when no oil is applied versus when oil is applied and if there is difference in the burn time of Agrabathi when coconut oil is applied as opposed to castor oil.

To account for these comparisons this study sets a maximum allowable experiment-wise type I error rate of $5%$. The comparisons are then corrected via the Bonferroni method to ensure this limit is upheld.

Formally we consider the following contrasts:
\begin{align*}
  L_1&=\mu_{Coconut}-\mu_{Castor}\\
  L_2&=\mu_{No\ Oil}-\frac{1}{2}(\mu_{Coconut}+\mu_{Castor})
\end{align*}
Note that $L_1$ and $L_2$ are orthogonal contrasts and thus partition the sum square treatment. The table below summarises the analysis of the contrasts.
```{r}
#| output: true

l1<-c(0,1,-1)
l2<-c(1,-0.5,-0.5)
mat<-cbind(l1,l2)
contrasts(genBurn$treat)<-mat
model <- aov(time ~ treat+block,data=genBurn)
tab<-unlist(summary.aov(model, split=list(treat=list("Coconut vs. Castor"=1, "Oil vs. No oil" = 2)))[1])

df<-data.frame(labs=c(1,2,3,4,6))
for(i in c(1,6,11,16,21)){
  df<-cbind(df,data.frame(unlist(tab[i:(i+4)])))
}
df$labs=NULL
rownames(df)<-c("Treatment","---L1","---L2","Error","Total")
colnames(df)<-c("DF","SS","MSS","F","P(>F)")

kbl(df,digits=c(1,1,1,3,4), format="latex",booktabs=TRUE, caption="Analysis of Contrasts")|>
kable_styling(position = "center", latex_options="hold_position")
```
This reveals an interesting nuance to the data. In the previous section we concluded that there is indeed an effect induced by the treatments. Contrast $L_2$ compares the effect of no oil to the effect of applying oil and this shows that there is a statistically significant difference between them with $p=8.79\times 10^{-6}$. Conversely contrast $L_1$ shows little effect ($p=0.60$) which is to say that there is little difference between the types of oil applied. 

Bonferroni corrected confidence intervals for these contrasts  are now constructed to ensure that the conclusions drawn above are valid and not simply type I errors. This study will permit a tolerance of $\alpha=5\%$ for type I errors. This is to say that the conclusions are drawn with $95\%$ confidence. The choice of Bonferroni's correction was made as only a priori contrasts are considered and there is  small number of them. Had the study performed a post hoc analysis and made all pairwise-comparisons more sophisticated methods such as Tukey's or Sheffe's would have been selected. 

```{r}
#| output: true
tabCI<-unlist(confint(model,c("treatl1","treatl2"),level=0.95))
df<-data.frame(tabCI)
df$est=(df$X2.5..+df$X97.5..)/2
colnames(df)<-c("Lower Bound","Upper Bound","Point Estimate")
rownames(df)<-c("Contrast L1","Contrast L2")

kbl(df,digits=3, format="latex",booktabs=TRUE, caption="Bonferroni corrected confidence intervals")|>
kable_styling(position = "center", latex_options="hold_position")

```
Based on these intervals the conclusions drawn by the initial analysis of the p-values is correct as the CI for L1 contains zero thus there is no significant difference between the oils. Similarly the CI for L2 does not contain zero and thus there is a difference between the application of oil versus no oil. \todo{talk about correctio n}

# Conclusion
The purpose of this experiment was to determine whether different oils affected the burn time of Agrabathi sticks. We posed questions of interest as to whether outcomes differed based on the type of oil used and whether it was impactful to use oil at all. Our contrasts were formulated around these questions and their results proved that the type of oil used did not matter yet using oil compared to no oil had a significant impact. 
Our null hypothesis was that oil had no impact on the burn time of Agrabathi, essentially saying that the old wives tale was completely wrong and using oil compared to no oil produced the same burn time (the type of oil was irrelevant). From our contrasts and the data from our ANOVA table, we rejected our null hypothesis. We remain confident in this decision since our p value <0.05 showing that the data is extremely unlikely if our null hypothesis was true.  
While we made considerable efforts to ensure the validity of this experiment—by randomizing the assignment of treatments, blocking for different Agrabathi brands to account for external variances, and conducting statistical tests to confirm that our data met the assumptions for ANOVA (such as equal variances, normality, and independence between experimental units)—there are still areas where improvements could be made.
One notable strength of the experiment was the successful execution of a pilot study. The pilot provided valuable insights into the experimental process, helping us refine the procedure before the full experiment. From this pilot, we confirmed that the data was homoscedastic (equal variances), which is a critical assumption for ANOVA. However, it also revealed that the data was not normally distributed. This deviation from normality, while not invalidating the experiment, could have impacted the precision of the results. In future studies, we might consider using transformations or non-parametric tests to account for non-normal data, or we could explore alternative experimental designs to better capture the true distribution of the data.
In terms of environmental control, although we minimized external influences, conducting the experiment outdoors introduced some variability due to fluctuations in temperature, wind, and sunlight. A more controlled environment—such as a large, empty room—would have reduced these variances and provided more reliable measurements of burn time.
Additionally, the financial feasibility of using oils like castor and coconut oil was not fully explored in this study. Future research could incorporate an analysis of the cost-benefit ratio to help users decide whether the investment in these oils is justified based on their impact on burn time. By adding this practical layer, the results could be more useful for families looking to balance tradition and cost-effectiveness.
Lastly, increasing the number of blocks and treatments would enhance the robustness and generalizability of the findings. Exploring a wider variety of brands and oils could lead to more comprehensive conclusions, providing greater insight into the factors that influence burn time.
In conclusion, our experiment provided some valuable insights into traditional practices and offers practical advice for modern users. By understanding how different oils impact burn time, we can make more informed decisions about their use in cultural and spiritual practices.

\newpage
# Appendix 
The original randomisation used is given below:
```{r}
#| output: true
#example randomisation

sampRand <-data.frame()

for (j in 1:30){
  for (i in 1:3){
  set.seed(sample(1:1000000))
  randOrd<-sample(1:1000,3)
  sorted<-sort(randOrd)
  treat<-match(sorted,randOrd)
  treat<-replace(treat, TRUE, LETTERS[unlist(treat)])
  sampRand<- rbind(sampRand,treat)
  }
}

sampRand<-cbind(c(rep("Hem",30), rep("Malarani",30) , rep("Tulasi",30)),sampRand)
colnames(sampRand)<-c("Block",1,2,3)
sampRand<-sampRand[sample(nrow(sampRand)),]
rownames(sampRand)<- NULL
kbl(sampRand, format="latex",booktabs=TRUE, longtable= TRUE, caption="Randomisation within blocks", row.names=NA)|>
kable_styling(position = "center", latex_options="hold_position")
```
The full data (after sorting) for the experiment is given below:

```{r}
#| output: true

modGenBurn<-genBurn
modGenBurn$time<-round(modGenBurn$time,2)
kbl(genBurn, longtable = TRUE, format="latex",booktabs=TRUE, caption="Randomisation within blocks", row.names=NA)|>
kable_styling(position = "center", latex_options="hold_position")
```

```{r}
#| eval: false
#Generation of data
n<- 10 #number of replications witin block

blocks<- c(1,2,3)
treat<- c("A","B","C")
std<-sd(pilotBurn$time)

df<-data.frame()
#set up columns
for (i in 1:3){
  block<- rep(i, times=n)
  treatment<-rep(treat,c(n,n,n)) 
  df<-rbind(df,cbind(block,treatment)) 
}
#generate data
times<-c()
for (i in 1:3){ #block
  #get means for each treatment within block
  means<- aov(time~treat,data=filter(pilotBurn, as.integer(block)==i))|>
         model.tables("means")
  means<- unname(unlist(means)[2:4])
  for (meanval in means){
    times<-c(times,rnorm(n,mean=meanval,sd=std))
  }
}
df<-cbind(df,time=times)
write.csv(df,row.names=FALSE,file="gendata.csv")
```
```{r}
#The pilot study full code
#| output: false
#| eval: false
data_raw<-read.csv(file="AgrabathiBurnTimePilotData.csv")
par(mfrow=c(1,1))
boxplot(min*60+sec ~ treat, data=data_raw, ylab="Burn Time (seconds)", xlab="Treatments", las=1, main="Boxplot of Pilot Study Data", col="pink")
data_raw

treat<-as.factor(data_raw$treat)
treat

#Mainly estimates
pilot<-aov(min*60+sec ~ treat, data=data_raw)
summary(pilot)
model.tables(pilot,"means")#Gives the mean
model.tables(pilot, se=T)#Gives the standard error of effects

#Normality tests
par(mfrow=c(2,3))
plot(pilot)

hist(resid(pilot), main=" ", las=1, breaks=10)

shapiro.test(resid(pilot))

#Checking equal variance

with(data_raw, tapply(min*60+sec, treat, sd))
#install.packages("car")

burn_time<-data_raw$min*60 +data_raw$sec
burn_time
leveneTest(min*60 +sec ~ treat, data=data_raw) 
#Since p value is 0.7526, assumption of equal variances is met since variances are not sig different.
par(mfrow=c(1,2))
hist(burn_time, main="", las=1, xlab="Burn Time")
qqPlot(burn_time) #Does look like data came from the same theoretical normal distr.

shapiro.test(burn_time)

```

Normality tests:
Fitted vs residuals: Should test for linearity, unequal error variances and outliers. The data should be randomly located around the horizontal line, there should be no extreme outliers, and the residual spread should be roughly constant against the fitted values to suggest homoscedasticity. Our graph does not show any extreme funnel shape but there is a widening as we move right through the plot indicating a potential loss of homoscedasticity.  
QQ plot: The most important test for normality, the data is basically supposed to stay on the 45 degree line but ours deviates into almost an S shape which indicates skewness. Since this is the most important test of normality and the Shapiro test is very accurate for small data sizes such as ours, this does not inspire confidence in our normal assumption which appears to be violated. 
Scale Location: This plot checks for homoscedasticity. The red line should be horizontal if the variance is constant. Our red line decreases, showing that variance is likely not constant. 
Constant Leverage: Similar to our fitted vs residuals, should be scattered around 0 with no discernible pattern. 
Our final histogram: No clear bell shape, there seems to be a positive skew. There is no symmetry in this graph. 
